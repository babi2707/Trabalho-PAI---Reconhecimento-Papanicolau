{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babi2707/Trabalho-PAI---Reconhecimento-Papanicolau/blob/main/algoritmo/backend/RedeNeural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 1:\n",
        "import zipfile\n",
        "\n",
        "caminho_pasta_compactada = '/content/sub_images.zip'\n",
        "caminho_destino = '/content/sub_images'\n",
        "\n",
        "with zipfile.ZipFile(caminho_pasta_compactada, 'r') as zip_ref:\n",
        "    zip_ref.extractall(caminho_destino)"
      ],
      "metadata": {
        "id": "fKGBtCoMnk8X"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 2:\n",
        "import os\n",
        "\n",
        "base_dir = '/content/sub_images/sub_images'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "classes = ['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative for intraepithelial lesion', 'SCC']\n",
        "for class_name in classes:\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)"
      ],
      "metadata": {
        "id": "ZR8TdzBhnKl0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 3:\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "import os\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import cv2\n",
        "\n",
        "# Diretório onde estão os dados\n",
        "data_dir = '/content/sub_images/sub_images'\n",
        "\n",
        "# Lista para armazenar os nomes dos arquivos e suas respectivas classes\n",
        "file_names = []\n",
        "labels = []\n",
        "\n",
        "# Preencher as listas com os nomes dos arquivos e suas classes correspondentes\n",
        "classes = ['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative for intraepithelial lesion', 'SCC']  # Adicionar os nomes das classes\n",
        "for class_name in classes:\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    for file_name in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, file_name)\n",
        "        file_names.append(file_path)\n",
        "        labels.append(class_name)\n",
        "\n",
        "# Dividir os dados em treino e teste mantendo a proporção de 4:1\n",
        "train_files, test_files, train_labels, test_labels = train_test_split(\n",
        "    file_names, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "\n",
        "# Função para extrair características de histograma de cor\n",
        "def extract_histogram_features(image_path, h_bins=16, s_bins=8):\n",
        "    image = cv2.imread(image_path)\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hist = cv2.calcHist([hsv_image], [0, 1], None, [h_bins, s_bins], [0, 180, 0, 256])\n",
        "    cv2.normalize(hist, hist)\n",
        "    return hist.flatten()\n",
        "\n",
        "# Extrair características das imagens de treino\n",
        "train_features = [extract_histogram_features(file_path) for file_path in train_files]\n",
        "\n",
        "# Aplicar oversampling no conjunto de treino\n",
        "smote = SMOTE(random_state=42)\n",
        "train_features, train_labels = smote.fit_resample(np.array(train_features), train_labels)\n",
        "\n",
        "# Verificar o balanceamento das classes nos conjuntos de treino e teste\n",
        "unique, counts = np.unique(train_labels, return_counts=True)\n",
        "print(f'Balanceamento das classes no conjunto de treino:')\n",
        "for class_name, count in zip(unique, counts):\n",
        "    print(f'Classe {class_name}: {count} amostras')\n",
        "\n",
        "# Atualizar o train_files após o oversampling\n",
        "train_files = [file_names[i] for i in range(len(train_files))]\n",
        "\n",
        "# Balancear o conjunto de testes via oversampling\n",
        "balanced_test_files = []\n",
        "balanced_test_labels = []\n",
        "\n",
        "# Encontrar a classe majoritária no conjunto de teste\n",
        "max_test_class_count = max([test_labels.count(c) for c in set(test_labels)])\n",
        "\n",
        "# Aplicar oversampling em cada classe no conjunto de teste\n",
        "for class_name in set(test_labels):\n",
        "    class_test_files = [file for file, label in zip(test_files, test_labels) if label == class_name]\n",
        "    class_test_labels = [label for label in test_labels if label == class_name]\n",
        "\n",
        "    # Oversampling\n",
        "    if len(class_test_files) < max_test_class_count:\n",
        "        class_test_files, class_test_labels = resample(\n",
        "            class_test_files, class_test_labels, replace=True, n_samples=max_test_class_count, random_state=42)\n",
        "\n",
        "    balanced_test_files.extend(class_test_files)\n",
        "    balanced_test_labels.extend(class_test_labels)\n",
        "\n",
        "# Verificar o balanceamento das classes no conjunto de teste balanceado\n",
        "unique, counts = np.unique(balanced_test_labels, return_counts=True)\n",
        "print(f'Balanceamento das classes no conjunto de teste balanceado:')\n",
        "for class_name, count in zip(unique, counts):\n",
        "    print(f'Classe {class_name}: {count} amostras')"
      ],
      "metadata": {
        "id": "KeuHTdp8ktEQ",
        "outputId": "a6c02ef0-9971-436f-d7ec-39d243a0ef7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanceamento das classes no conjunto de treino:\n",
            "Classe ASC-H: 3395 amostras\n",
            "Classe ASC-US: 3395 amostras\n",
            "Classe HSIL: 3395 amostras\n",
            "Classe LSIL: 3395 amostras\n",
            "Classe Negative for intraepithelial lesion: 3395 amostras\n",
            "Classe SCC: 3395 amostras\n",
            "Balanceamento das classes no conjunto de teste:\n",
            "Classe ASC-H: 17 amostras\n",
            "Classe ASC-US: 78 amostras\n",
            "Classe HSIL: 58 amostras\n",
            "Classe LSIL: 99 amostras\n",
            "Classe Negative for intraepithelial lesion: 849 amostras\n",
            "Classe SCC: 16 amostras\n",
            "Balanceamento das classes no conjunto de teste balanceado:\n",
            "Classe ASC-H: 849 amostras\n",
            "Classe ASC-US: 849 amostras\n",
            "Classe HSIL: 849 amostras\n",
            "Classe LSIL: 849 amostras\n",
            "Classe Negative for intraepithelial lesion: 849 amostras\n",
            "Classe SCC: 849 amostras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 4:\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def split_data(source_dir, train_dir, test_dir):\n",
        "    for class_name in classes:\n",
        "        class_dir = os.path.join(source_dir, class_name)\n",
        "        train_class_dir = os.path.join(train_dir, class_name)\n",
        "        test_class_dir = os.path.join(test_dir, class_name)\n",
        "\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(test_class_dir, exist_ok=True)\n",
        "\n",
        "        for image in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, image)\n",
        "            if image_path in train_files:\n",
        "                dest_path = os.path.join(train_class_dir, image)\n",
        "                if not os.path.exists(dest_path):\n",
        "                    shutil.copy2(image_path, dest_path)\n",
        "                else:\n",
        "                    # Renomear o arquivo se já existir\n",
        "                    base, ext = os.path.splitext(image)\n",
        "                    new_dest_path = os.path.join(train_class_dir, f\"{base}_copy{ext}\")\n",
        "                    shutil.copy2(image_path, new_dest_path)\n",
        "            elif image_path in balanced_test_files:\n",
        "                dest_path = os.path.join(test_class_dir, image)\n",
        "                if not os.path.exists(dest_path):\n",
        "                    shutil.copy2(image_path, dest_path)\n",
        "                else:\n",
        "                    # Renomear o arquivo se já existir\n",
        "                    base, ext = os.path.splitext(image)\n",
        "                    new_dest_path = os.path.join(test_class_dir, f\"{base}_copy{ext}\")\n",
        "                    shutil.copy2(image_path, new_dest_path)\n",
        "\n",
        "split_data(data_dir, train_dir, test_dir)"
      ],
      "metadata": {
        "id": "zlJMfiFdnNvB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5.2 - SVM:\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import joblib\n",
        "import h5py\n",
        "\n",
        "def extract_histogram_features(image_path, h_bins=16, s_bins=8):\n",
        "    image = cv2.imread(image_path)\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hist = cv2.calcHist([hsv_image], [0, 1], None, [h_bins, s_bins], [0, 180, 0, 256])\n",
        "    cv2.normalize(hist, hist)\n",
        "    return hist.flatten()\n",
        "\n",
        "train_features = []\n",
        "train_labels_hist = []\n",
        "test_features = []\n",
        "test_labels_hist = []\n",
        "\n",
        "for file_path, label in zip(train_files, train_labels):\n",
        "    features = extract_histogram_features(file_path)\n",
        "    train_features.append(features)\n",
        "    train_labels_hist.append(label)\n",
        "\n",
        "for file_path, label in zip(balanced_test_files, balanced_test_labels):\n",
        "    features = extract_histogram_features(file_path)\n",
        "    test_features.append(features)\n",
        "    test_labels_hist.append(label)\n",
        "\n",
        "train_features = np.array(train_features)\n",
        "test_features = np.array(test_features)\n",
        "\n",
        "# Codificar as classes\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels_hist)\n",
        "test_labels_encoded = label_encoder.transform(test_labels_hist)\n",
        "\n",
        "# Padronizar as características\n",
        "scaler = StandardScaler()\n",
        "train_features_scaled = scaler.fit_transform(train_features)\n",
        "test_features_scaled = scaler.transform(test_features)\n",
        "\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(train_features_scaled, train_labels_encoded)\n",
        "\n",
        "# Salvar o modelo usando joblib\n",
        "joblib.dump(svm_model, 'svm_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "j7m8o8ayia9F",
        "outputId": "3dbbf691-721c-4f34-fdc1-2c8c91016deb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5.3 - Resnet50:\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Parameters\n",
        "img_height, img_width = 100, 100\n",
        "batch_size = 32\n",
        "num_classes = 6\n",
        "class_names = ['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative for intraepithelial lesion', 'SCC']\n",
        "\n",
        "# Data augmentation\n",
        "# Data augmentation\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=60,  # Aumentado para 60 graus\n",
        "    width_shift_range=0.4,  # Aumentado para 0.4\n",
        "    height_shift_range=0.4,  # Aumentado para 0.4\n",
        "    shear_range=0.4,\n",
        "    zoom_range=0.4,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen_val_test = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = datagen_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = datagen_val_test.flow_from_directory(\n",
        "    test_dir,  # usando test_dir para validação neste exemplo\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = datagen_val_test.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)  # Reduzindo para 512 unidades\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)  # Reduzindo para uma taxa de dropout de 0.4\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Primeira fase de treinamento\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator),\n",
        "    epochs=30\n",
        ")\n",
        "\n",
        "# Fine-tuning\n",
        "for layer in base_model.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpoint_filepath = '/content/modelo_resnet50_best.h5'\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=test_generator,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "\n",
        "# Carregar o melhor modelo salvo durante o treinamento\n",
        "model.load_weights(checkpoint_filepath)\n",
        "\n",
        "# Salvar o modelo final\n",
        "model.save('/content/modelo_resnet50.h5')\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB7PmHLrNZN4",
        "outputId": "366a49d5-98e2-41c8-9f52-a8f877926d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9007 images belonging to 6 classes.\n",
            "Found 717 images belonging to 6 classes.\n",
            "Found 717 images belonging to 6 classes.\n",
            "Epoch 1/30\n",
            "282/282 [==============================] - 47s 152ms/step - loss: 2.7597 - accuracy: 0.2135 - val_loss: 2.8648 - val_accuracy: 0.0307\n",
            "Epoch 2/30\n",
            "282/282 [==============================] - 37s 133ms/step - loss: 2.5578 - accuracy: 0.2813 - val_loss: 2.1668 - val_accuracy: 0.6165\n",
            "Epoch 3/30\n",
            "282/282 [==============================] - 39s 138ms/step - loss: 2.4301 - accuracy: 0.3294 - val_loss: 1.7003 - val_accuracy: 0.7434\n",
            "Epoch 4/30\n",
            "282/282 [==============================] - 37s 131ms/step - loss: 2.2988 - accuracy: 0.3722 - val_loss: 2.0221 - val_accuracy: 0.6262\n",
            "Epoch 5/30\n",
            "282/282 [==============================] - 41s 146ms/step - loss: 2.1727 - accuracy: 0.4340 - val_loss: 2.1012 - val_accuracy: 0.5565\n",
            "Epoch 6/30\n",
            "282/282 [==============================] - 38s 135ms/step - loss: 2.0748 - accuracy: 0.4632 - val_loss: 1.9646 - val_accuracy: 0.2357\n",
            "Epoch 7/30\n",
            "282/282 [==============================] - 37s 130ms/step - loss: 1.9669 - accuracy: 0.5178 - val_loss: 1.7336 - val_accuracy: 0.6095\n",
            "Epoch 8/30\n",
            "282/282 [==============================] - 38s 133ms/step - loss: 1.8753 - accuracy: 0.5595 - val_loss: 1.6322 - val_accuracy: 0.7308\n",
            "Epoch 9/30\n",
            "282/282 [==============================] - 37s 132ms/step - loss: 1.7914 - accuracy: 0.5901 - val_loss: 1.5800 - val_accuracy: 0.7629\n",
            "Epoch 10/30\n",
            "282/282 [==============================] - 37s 131ms/step - loss: 1.7076 - accuracy: 0.6153 - val_loss: 2.3657 - val_accuracy: 0.0391\n",
            "Epoch 11/30\n",
            "282/282 [==============================] - 37s 131ms/step - loss: 1.6362 - accuracy: 0.6373 - val_loss: 1.8481 - val_accuracy: 0.4073\n",
            "Epoch 12/30\n",
            "282/282 [==============================] - 37s 133ms/step - loss: 1.5742 - accuracy: 0.6544 - val_loss: 1.1116 - val_accuracy: 0.8020\n",
            "Epoch 13/30\n",
            "282/282 [==============================] - 37s 131ms/step - loss: 1.5148 - accuracy: 0.6690 - val_loss: 1.3639 - val_accuracy: 0.7615\n",
            "Epoch 14/30\n",
            "282/282 [==============================] - 36s 128ms/step - loss: 1.4688 - accuracy: 0.6792 - val_loss: 1.0750 - val_accuracy: 0.8103\n",
            "Epoch 15/30\n",
            "282/282 [==============================] - 37s 133ms/step - loss: 1.4235 - accuracy: 0.6842 - val_loss: 1.0995 - val_accuracy: 0.8089\n",
            "Epoch 16/30\n",
            "282/282 [==============================] - 38s 133ms/step - loss: 1.3912 - accuracy: 0.6939 - val_loss: 1.5389 - val_accuracy: 0.7308\n",
            "Epoch 17/30\n",
            "282/282 [==============================] - 50s 179ms/step - loss: 1.3662 - accuracy: 0.6940 - val_loss: 1.0539 - val_accuracy: 0.8047\n",
            "Epoch 18/30\n",
            "282/282 [==============================] - 37s 132ms/step - loss: 1.3353 - accuracy: 0.6976 - val_loss: 1.1424 - val_accuracy: 0.7964\n",
            "Epoch 19/30\n",
            "282/282 [==============================] - 37s 132ms/step - loss: 1.3186 - accuracy: 0.6973 - val_loss: 1.0730 - val_accuracy: 0.8103\n",
            "Epoch 20/30\n",
            "282/282 [==============================] - 37s 132ms/step - loss: 1.3022 - accuracy: 0.7025 - val_loss: 1.7199 - val_accuracy: 0.5174\n",
            "Epoch 21/30\n",
            "282/282 [==============================] - 37s 132ms/step - loss: 1.2869 - accuracy: 0.7050 - val_loss: 1.1488 - val_accuracy: 0.7992\n",
            "Epoch 22/30\n",
            "282/282 [==============================] - 36s 129ms/step - loss: 1.2837 - accuracy: 0.7040 - val_loss: 1.0614 - val_accuracy: 0.7936\n",
            "Epoch 23/30\n",
            "282/282 [==============================] - 37s 132ms/step - loss: 1.2629 - accuracy: 0.7079 - val_loss: 1.4816 - val_accuracy: 0.6555\n",
            "Epoch 24/30\n",
            "282/282 [==============================] - 41s 146ms/step - loss: 1.2549 - accuracy: 0.7107 - val_loss: 1.2264 - val_accuracy: 0.7880\n",
            "Epoch 25/30\n",
            "282/282 [==============================] - 37s 132ms/step - loss: 1.2558 - accuracy: 0.7083 - val_loss: 1.0117 - val_accuracy: 0.8089\n",
            "Epoch 26/30\n",
            "282/282 [==============================] - 38s 134ms/step - loss: 1.2422 - accuracy: 0.7093 - val_loss: 1.0834 - val_accuracy: 0.8103\n",
            "Epoch 27/30\n",
            "282/282 [==============================] - 37s 132ms/step - loss: 1.2394 - accuracy: 0.7112 - val_loss: 1.0844 - val_accuracy: 0.8075\n",
            "Epoch 28/30\n",
            "282/282 [==============================] - 38s 134ms/step - loss: 1.2311 - accuracy: 0.7107 - val_loss: 1.2843 - val_accuracy: 0.8103\n",
            "Epoch 29/30\n",
            "282/282 [==============================] - 37s 130ms/step - loss: 1.2284 - accuracy: 0.7093 - val_loss: 1.0304 - val_accuracy: 0.8089\n",
            "Epoch 30/30\n",
            " 75/282 [======>.......................] - ETA: 27s - loss: 1.2395 - accuracy: 0.7092"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5.4 - Resnet50 (Binary Classifier)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "img_height, img_width = 100, 100\n",
        "batch_size = 32\n",
        "num_classes = 2\n",
        "\n",
        "# Data augmentation\n",
        "datagen_train_bin = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=50,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen_val_test_bin = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_bin = datagen_train_bin.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator_bin = datagen_val_test_bin.flow_from_directory(\n",
        "    test_dir,  # usando test_dir para validação neste exemplo\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator_bin = datagen_val_test_bin.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Model\n",
        "base_model_bin = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "x = base_model_bin.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "predictions_bin = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Ajuste de aumento de dados para o modelo binário\n",
        "datagen_train_bin = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=50,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "model_bin = Model(inputs=base_model_bin.input, outputs=predictions_bin)\n",
        "\n",
        "for layer in base_model_bin.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilar e treinar o modelo binário\n",
        "model_bin.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "history_bin = model_bin.fit(\n",
        "    train_generator_bin,\n",
        "    steps_per_epoch=len(train_generator_bin),\n",
        "    validation_data=val_generator_bin,\n",
        "    validation_steps=len(val_generator_bin),\n",
        "    epochs=30\n",
        ")\n",
        "\n",
        "# Avaliar o modelo binário\n",
        "test_loss_bin, test_acc_bin = model_bin.evaluate(test_generator_bin)\n",
        "\n",
        "# Previsões no conjunto de teste binário\n",
        "predictions_bin = model_bin.predict(test_generator_bin)\n",
        "predicted_classes_bin = np.where(predictions_bin > 0.5, 1, 0)\n",
        "\n",
        "true_classes_bin = test_generator_bin.classes\n",
        "class_labels_bin = list(test_generator_bin.class_indices.keys())\n",
        "\n",
        "# Métricas de avaliação\n",
        "binary_accuracy_bin = accuracy_score(true_classes_bin, predicted_classes_bin)\n",
        "conf_matrix_bin = confusion_matrix(true_classes_bin, predicted_classes_bin)\n",
        "classification_report_bin = classification_report(true_classes_bin, predicted_classes_bin, target_names=class_labels_bin)\n",
        "\n",
        "print(f'Binary ResNet50 Classifier Accuracy: {binary_accuracy_bin}')\n",
        "print('Binary ResNet50 Classifier Confusion Matrix:')\n",
        "print(conf_matrix_bin)\n",
        "print('Binary ResNet50 Classifier Classification Report:')\n",
        "print(classification_report_bin)"
      ],
      "metadata": {
        "id": "Q6Nym-Mg-KST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 6.2 - SVM:\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Classificador binário (classe negativa X demais)\n",
        "binary_labels_train = np.where(train_labels_encoded == 4, 0, 1)  # 'Negative for intraepithelial lesion' = 4\n",
        "binary_labels_test = np.where(test_labels_encoded == 4, 0, 1)\n",
        "\n",
        "svm_binary = SVC(kernel='linear')\n",
        "svm_binary.fit(train_features_scaled, binary_labels_train)\n",
        "binary_predictions = svm_binary.predict(test_features_scaled)\n",
        "\n",
        "# Classificador multiclasse (6 classes)\n",
        "svm_multiclass = SVC(kernel='linear')\n",
        "svm_multiclass.fit(train_features_scaled, train_labels_encoded)\n",
        "multiclass_predictions = svm_multiclass.predict(test_features_scaled)\n",
        "\n",
        "# Avaliação do classificador binário\n",
        "binary_accuracy = accuracy_score(binary_labels_test, binary_predictions)\n",
        "binary_conf_matrix = confusion_matrix(binary_labels_test, binary_predictions)\n",
        "print('Binary Classifier Accuracy:', binary_accuracy)\n",
        "print('Binary Classifier Confusion Matrix:')\n",
        "print(binary_conf_matrix)\n",
        "print('Binary Classifier Classification Report:')\n",
        "print(classification_report(binary_labels_test, binary_predictions, target_names=['Negative', 'Others']))\n",
        "\n",
        "# Avaliação do classificador multiclasse\n",
        "multiclass_accuracy = accuracy_score(test_labels_encoded, multiclass_predictions)\n",
        "multiclass_conf_matrix = confusion_matrix(test_labels_encoded, multiclass_predictions)\n",
        "print('Multiclass Classifier Accuracy:', multiclass_accuracy)\n",
        "print('Multiclass Classifier Confusion Matrix:')\n",
        "print(multiclass_conf_matrix)\n",
        "print('Multiclass Classifier Classification Report:')\n",
        "print(classification_report(test_labels_encoded, multiclass_predictions, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "id": "TJJdgECAghLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Célula 6.3 - Resnet50:\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import math  # Importar o módulo math\n",
        "\n",
        "# Função para plotar gráfico de aprendizado\n",
        "def plot_learning_curves(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Previsões no conjunto de teste para ResNet50\n",
        "test_steps_per_epoch = math.ceil(test_generator.samples / test_generator.batch_size)\n",
        "predictions_resnet = model.predict(test_generator, steps=test_steps_per_epoch)\n",
        "predicted_classes_resnet = np.argmax(predictions_resnet, axis=1)\n",
        "\n",
        "# True labels para ResNet50\n",
        "true_classes_resnet = test_generator.classes\n",
        "class_labels_resnet = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Acurácia e relatório de classificação para ResNet50\n",
        "accuracy_resnet = accuracy_score(true_classes_resnet, predicted_classes_resnet)\n",
        "conf_matrix_resnet = confusion_matrix(true_classes_resnet, predicted_classes_resnet)\n",
        "classification_report_resnet = classification_report(true_classes_resnet, predicted_classes_resnet, target_names=class_labels_resnet)\n",
        "\n",
        "print(f'ResNet50 Classifier Accuracy: {accuracy_resnet}')\n",
        "print('ResNet50 Classifier Confusion Matrix:')\n",
        "print(conf_matrix_resnet)\n",
        "print('ResNet50 Classifier Classification Report:')\n",
        "print(classification_report_resnet)\n",
        "\n",
        "# Plotar curvas de aprendizado\n",
        "plot_learning_curves(history)"
      ],
      "metadata": {
        "id": "0J9RROeAM_RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 7 - Comparação dos Resultados ResNet50\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "test_steps_per_epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)\n",
        "predictions = model.predict(test_generator, steps=test_steps_per_epoch)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# True labels\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Acurácia e relatório de classificação\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "classification_report_resnet = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "\n",
        "print(f'ResNet50 Classifier Accuracy: {accuracy}')\n",
        "print('ResNet50 Classifier Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('ResNet50 Classifier Classification Report:')\n",
        "print(classification_report_resnet)\n",
        "\n",
        "# Plotar curvas de aprendizado\n",
        "plot_learning_curves(history)"
      ],
      "metadata": {
        "id": "ZDnA3aGF8TYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Célula 8:\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Função para plotar gráfico de aprendizado\n",
        "def plot_learning_curves(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plotar curvas de aprendizado para ResNet50\n",
        "plot_learning_curves(history)\n",
        "\n",
        "# Previsões no conjunto de teste para ResNet50\n",
        "test_steps_per_epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)\n",
        "predictions_resnet = model.predict(test_generator, steps=test_steps_per_epoch)\n",
        "predicted_classes_resnet = np.argmax(predictions_resnet, axis=1)\n",
        "\n",
        "# True labels para ResNet50\n",
        "true_classes_resnet = test_generator.classes\n",
        "class_labels_resnet = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Acurácia e relatório de classificação para ResNet50\n",
        "accuracy_resnet = accuracy_score(true_classes_resnet, predicted_classes_resnet)\n",
        "conf_matrix_resnet = confusion_matrix(true_classes_resnet, predicted_classes_resnet)\n",
        "classification_report_resnet = classification_report(true_classes_resnet, predicted_classes_resnet, target_names=class_labels_resnet)\n",
        "\n",
        "print(f'ResNet50 Classifier Accuracy: {accuracy_resnet}')\n",
        "print('ResNet50 Classifier Confusion Matrix:')\n",
        "print(conf_matrix_resnet)\n",
        "print('ResNet50 Classifier Classification Report:')\n",
        "print(classification_report_resnet)\n",
        "\n",
        "# Comparação de Acurácia\n",
        "print(\"==== Comparação de Acurácia ====\")\n",
        "print(f'SVM Binary Classifier Accuracy: {binary_accuracy}')\n",
        "print(f'SVM Multiclass Classifier Accuracy: {multiclass_accuracy}')\n",
        "print(f'ResNet50 Classifier Accuracy: {accuracy}')\n",
        "print(f'ResNet50 Binary Classifier Accuracy: {binary_accuracy_bin}')\n",
        "\n",
        "# Comparação de Matrizes de Confusão\n",
        "print(\"\\n==== Matrizes de Confusão ====\")\n",
        "print(\"SVM Binary Classifier Confusion Matrix:\")\n",
        "print(binary_conf_matrix)\n",
        "print(\"\\nSVM Multiclass Classifier Confusion Matrix:\")\n",
        "print(multiclass_conf_matrix)\n",
        "print(\"\\nResNet50 Classifier Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nResNet50 Binary Classifier Confusion Matrix:\")\n",
        "print(conf_matrix_bin)\n",
        "\n",
        "# Comparação de Relatórios de Classificação\n",
        "print(\"\\n==== Relatórios de Classificação ====\")\n",
        "print(\"SVM Binary Classifier Classification Report:\")\n",
        "print(classification_report(binary_labels_test, binary_predictions, target_names=['Negative', 'Others']))\n",
        "print(\"\\nSVM Multiclass Classifier Classification Report:\")\n",
        "print(classification_report(test_labels_encoded, multiclass_predictions, target_names=label_encoder.classes_))\n",
        "print(\"\\nResNet50 Classifier Classification Report:\")\n",
        "print(classification_report(true_classes, predicted_classes_resnet, target_names=class_labels_resnet))\n",
        "# Assuming true_classes_bin and predicted_classes_bin have 6 classes similar to other reports\n",
        "class_labels_bin = ['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative for intraepithelial lesion', 'SCC']\n",
        "\n",
        "print(\"\\nResNet50 Binary Classifier Classification Report:\")\n",
        "print(classification_report(true_classes_bin, predicted_classes_bin, target_names=class_labels_bin))\n",
        "\n",
        "\n",
        "# Configurações gerais para os gráficos\n",
        "plt.style.use('seaborn')\n",
        "sns.set(font_scale=1.2)\n",
        "\n",
        "# 1. Gráfico de Barras para Acurácia\n",
        "accuracies = [binary_accuracy, multiclass_accuracy, accuracy, accuracy_resnet]\n",
        "models = ['SVM Binary', 'SVM Multiclass', 'ResNet50 Multiclass', 'ResNet50 Binary']\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(models, accuracies, color=['blue', 'green', 'red', 'purple'])\n",
        "plt.ylabel('Acurácia')\n",
        "plt.title('Comparação de Acurácia entre os Classificadores')\n",
        "plt.ylim(0, 1)\n",
        "for i, acc in enumerate(accuracies):\n",
        "    plt.text(i, acc + 0.02, f'{acc:.2f}', ha='center', va='bottom')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2. Heatmaps para Matrizes de Confusão\n",
        "conf_matrices = [binary_conf_matrix, multiclass_conf_matrix, conf_matrix, conf_matrix_bin]\n",
        "titles = ['SVM Binary', 'SVM Multiclass', 'ResNet50 Multiclass', 'ResNet50 Binary']\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, conf_matrix, title in zip(axes, conf_matrices, titles):\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('Predito')\n",
        "    ax.set_ylabel('Verdadeiro')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Gráficos de Barras para Métricas de Classificação\n",
        "# Métricas de classificação: precisão, recall, F1-score\n",
        "binary_metrics = precision_recall_fscore_support(binary_labels_test, binary_predictions, average='binary')[:3]\n",
        "multiclass_metrics = precision_recall_fscore_support(test_labels_encoded, multiclass_predictions, average='weighted')[:3]\n",
        "resnet_metrics = precision_recall_fscore_support(true_classes, predicted_classes_resnet, average='weighted')[:3]\n",
        "resnet_bin_metrics = precision_recall_fscore_support(true_classes_bin, predicted_classes_bin, average='weighted')[:3]\n",
        "\n",
        "metrics = ['Precisão', 'Recall', 'F1-Score']\n",
        "binary_values = [binary_metrics[0], binary_metrics[1], binary_metrics[2]]\n",
        "multiclass_values = [multiclass_metrics[0], multiclass_metrics[1], multiclass_metrics[2]]\n",
        "resnet_values = [resnet_metrics[0], resnet_metrics[1], resnet_metrics[2]]\n",
        "resnet_bin_values = [resnet_bin_metrics[0], resnet_bin_metrics[1], resnet_bin_metrics[2]]\n",
        "\n",
        "x = np.arange(len(metrics))  # localização dos rótulos\n",
        "width = 0.2  # largura das barras\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "rects1 = ax.bar(x - 1.5*width, binary_values, width, label='SVM Binary')\n",
        "rects2 = ax.bar(x - 0.5*width, multiclass_values, width, label='SVM Multiclass')\n",
        "rects3 = ax.bar(x + 0.5*width, resnet_values, width, label='ResNet50 Multiclass')\n",
        "rects4 = ax.bar(x + 1.5*width, resnet_bin_values, width, label='ResNet50 Binary')\n",
        "\n",
        "# Adicionar texto para os rótulos\n",
        "ax.set_xlabel('Métricas')\n",
        "ax.set_ylabel('Valores')\n",
        "ax.set_title('Comparação de Métricas de Classificação')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "\n",
        "def autolabel(rects):\n",
        "    \"\"\"Anexa um rótulo de texto acima de cada barra, exibindo seu valor.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.2f}',\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 pontos de deslocamento vertical\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "autolabel(rects3)\n",
        "autolabel(rects4)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vyznF8rq8WO2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}