{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babi2707/Trabalho-PAI---Reconhecimento-Papanicolau/blob/etapa2/algoritmo/backend/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 1:\n",
        "import zipfile\n",
        "\n",
        "caminho_pasta_compactada = '/content/sub_images.zip'\n",
        "caminho_destino = '/content/sub_images'\n",
        "\n",
        "with zipfile.ZipFile(caminho_pasta_compactada, 'r') as zip_ref:\n",
        "    zip_ref.extractall(caminho_destino)"
      ],
      "metadata": {
        "id": "fKGBtCoMnk8X"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 2:\n",
        "import os\n",
        "\n",
        "base_dir = '/content/sub_images/sub_images'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Criar diretórios principais\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Criar subdiretórios para cada classe\n",
        "classes = ['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative for intraepithelial lesion', 'SCC']\n",
        "for class_name in classes:\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)"
      ],
      "metadata": {
        "id": "ZR8TdzBhnKl0"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Célula 3.1:\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import os\n",
        "\n",
        "# # Diretório onde estão os dados\n",
        "# data_dir = '/content/sub_images/sub_images'\n",
        "\n",
        "# # Lista para armazenar os nomes dos arquivos e suas respectivas classes\n",
        "# file_names = []\n",
        "# labels = []\n",
        "\n",
        "# # Preencher as listas com os nomes dos arquivos e suas classes correspondentes\n",
        "# for class_name in os.listdir(data_dir):\n",
        "#     class_dir = os.path.join(data_dir, class_name)\n",
        "#     for file_name in os.listdir(class_dir):\n",
        "#         file_path = os.path.join(class_dir, file_name)\n",
        "#         file_names.append(file_path)\n",
        "#         labels.append(class_name)\n",
        "\n",
        "# # Dividir os dados em treino e validação (80% treino, 20% validação)\n",
        "# train_files, val_files, train_labels, val_labels = train_test_split(\n",
        "#     file_names, labels, test_size=0.2, stratify=labels, random_state=42\n",
        "# )\n",
        "\n",
        "# # Dividir os dados de treino em treino e teste (80% treino, 20% teste)\n",
        "# train_files, test_files, train_labels, test_labels = train_test_split(\n",
        "#     train_files, train_labels, test_size=0.2, stratify=train_labels, random_state=42\n",
        "# )\n",
        "\n",
        "# # Verificar o balanceamento das classes nos conjuntos de treino e teste\n",
        "# for dataset, dataset_name in zip([train_labels, test_labels], ['treino', 'teste']):\n",
        "#     unique, counts = np.unique(dataset, return_counts=True)\n",
        "#     print(f'Balanceamento das classes no conjunto de {dataset_name}:')\n",
        "#     for class_name, count in zip(unique, counts):\n",
        "#         print(f'Classe {class_name}: {count} amostras')\n",
        "\n",
        "# # Agora você tem:\n",
        "# # - train_files: lista de arquivos de treino\n",
        "# # - train_labels: lista de rótulos correspondentes de treino\n",
        "# # - val_files: lista de arquivos de validação\n",
        "# # - val_labels: lista de rótulos correspondentes de validação\n",
        "# # - test_files: lista de arquivos de teste\n",
        "# # - test_labels: lista de rótulos correspondentes de teste\n",
        "\n",
        "# #Resultados\n",
        "# # Found 966 images belonging to 6 classes.\n",
        "# # Found 685 images belonging to 6 classes.\n",
        "# # Found 704 images belonging to 6 classes.\n",
        "# # Epoch 1/10\n",
        "# # 31/31 [==============================] - 38s 158ms/step - loss: 2.9636 - accuracy: 0.2122 - val_loss: 1.7655 - val_accuracy: 0.2015\n",
        "# # Epoch 2/10\n",
        "# # 31/31 [==============================] - 3s 103ms/step - loss: 2.4541 - accuracy: 0.2402 - val_loss: 1.7478 - val_accuracy: 0.1985\n",
        "# # Epoch 3/10\n",
        "# # 31/31 [==============================] - 5s 156ms/step - loss: 2.2608 - accuracy: 0.2474 - val_loss: 1.7609 - val_accuracy: 0.1985\n",
        "# # Epoch 4/10\n",
        "# # 31/31 [==============================] - 3s 102ms/step - loss: 2.0217 - accuracy: 0.2826 - val_loss: 1.8062 - val_accuracy: 0.1985\n",
        "# # Epoch 5/10\n",
        "# # 31/31 [==============================] - 3s 100ms/step - loss: 1.9638 - accuracy: 0.2681 - val_loss: 1.7999 - val_accuracy: 0.1985\n",
        "# # Epoch 6/10\n",
        "# # 31/31 [==============================] - 3s 110ms/step - loss: 1.8415 - accuracy: 0.2867 - val_loss: 1.7896 - val_accuracy: 0.2234\n",
        "# # Epoch 7/10\n",
        "# # 31/31 [==============================] - 4s 143ms/step - loss: 1.8139 - accuracy: 0.2681 - val_loss: 1.7969 - val_accuracy: 0.2146\n",
        "# # Epoch 8/10\n",
        "# # 31/31 [==============================] - 3s 102ms/step - loss: 1.7435 - accuracy: 0.3033 - val_loss: 1.8410 - val_accuracy: 0.2219\n",
        "# # Epoch 9/10\n",
        "# # 31/31 [==============================] - 3s 105ms/step - loss: 1.7050 - accuracy: 0.2878 - val_loss: 1.8719 - val_accuracy: 0.2161\n",
        "# # Epoch 10/10\n",
        "# # 31/31 [==============================] - 5s 156ms/step - loss: 1.6880 - accuracy: 0.3095 - val_loss: 1.8447 - val_accuracy: 0.2263\n",
        "# # 31/31 [==============================] - 2s 51ms/step\n",
        "# # 22/22 [==============================] - 1s 49ms/step\n",
        "# # Validation Accuracy (SVM): 0.19416058394160585\n",
        "# #                                      precision    recall  f1-score   support\n",
        "\n",
        "# #                               ASC-H       0.11      0.08      0.09        60\n",
        "# #                              ASC-US       0.24      0.32      0.27       138\n",
        "# #                                HSIL       0.18      0.18      0.18       147\n",
        "# #                                LSIL       0.16      0.24      0.19       136\n",
        "# # Negative for intraepithelial lesion       0.25      0.16      0.19       144\n",
        "# #                                 SCC       0.16      0.05      0.08        60\n",
        "\n",
        "# #                            accuracy                           0.19       685\n",
        "# #                           macro avg       0.18      0.17      0.17       685\n",
        "# #                        weighted avg       0.19      0.19      0.19       685"
      ],
      "metadata": {
        "id": "x8Sr5yJVpc5G"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 3.2:\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Diretório onde estão os dados\n",
        "data_dir = '/content/sub_images/sub_images'\n",
        "\n",
        "# Lista para armazenar os nomes dos arquivos e suas respectivas classes\n",
        "file_names = []\n",
        "labels = []\n",
        "\n",
        "# Preencher as listas com os nomes dos arquivos e suas classes correspondentes\n",
        "for class_name in os.listdir(data_dir):\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    for file_name in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, file_name)\n",
        "        file_names.append(file_path)\n",
        "        labels.append(class_name)\n",
        "\n",
        "# Dividir os dados em treino e teste mantendo a proporção de 4:1\n",
        "train_files = []\n",
        "test_files = []\n",
        "train_labels = []\n",
        "test_labels = []\n",
        "\n",
        "# Para cada classe, dividir os arquivos em treino e teste mantendo a proporção de 4:1\n",
        "for class_name in set(labels):\n",
        "    # Obter os arquivos e rótulos da classe atual\n",
        "    class_files = [file for file, label in zip(file_names, labels) if label == class_name]\n",
        "    class_labels = [label for label in labels if label == class_name]\n",
        "\n",
        "    # Dividir os arquivos e rótulos em treino e teste\n",
        "    class_train_files, class_test_files, class_train_labels, class_test_labels = train_test_split(\n",
        "        class_files, class_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Adicionar os arquivos e rótulos aos conjuntos de treino e teste\n",
        "    train_files.extend(class_train_files)\n",
        "    test_files.extend(class_test_files)\n",
        "    train_labels.extend(class_train_labels)\n",
        "    test_labels.extend(class_test_labels)\n",
        "\n",
        "# Verificar o balanceamento das classes nos conjuntos de treino e teste\n",
        "for dataset, dataset_name in zip([train_labels, test_labels], ['treino', 'teste']):\n",
        "    unique, counts = np.unique(dataset, return_counts=True)\n",
        "    print(f'Balanceamento das classes no conjunto de {dataset_name}:')\n",
        "    for class_name, count in zip(unique, counts):\n",
        "        print(f'Classe {class_name}: {count} amostras')\n",
        "\n",
        "# Agora você tem:\n",
        "# - train_files: lista de arquivos de treino\n",
        "# - train_labels: lista de rótulos correspondentes de treino\n",
        "# - test_files: lista de arquivos de teste\n",
        "# - test_labels: lista de rótulos correspondentes de teste\n",
        "\n",
        "\n",
        "#Resultados:\n",
        "# Found 966 images belonging to 6 classes.\n",
        "# Found 728 images belonging to 6 classes.\n",
        "# Found 748 images belonging to 6 classes.\n",
        "# Epoch 1/10\n",
        "# 31/31 [==============================] - 35s 156ms/step - loss: 2.9200 - accuracy: 0.2112 - val_loss: 1.7805 - val_accuracy: 0.2102\n",
        "# Epoch 2/10\n",
        "# 31/31 [==============================] - 3s 110ms/step - loss: 2.4740 - accuracy: 0.2484 - val_loss: 1.7786 - val_accuracy: 0.2102\n",
        "# Epoch 3/10\n",
        "# 31/31 [==============================] - 3s 100ms/step - loss: 2.3013 - accuracy: 0.2516 - val_loss: 1.8061 - val_accuracy: 0.2102\n",
        "# Epoch 4/10\n",
        "# 31/31 [==============================] - 3s 99ms/step - loss: 2.0867 - accuracy: 0.2640 - val_loss: 1.8524 - val_accuracy: 0.2102\n",
        "# Epoch 5/10\n",
        "# 31/31 [==============================] - 5s 168ms/step - loss: 1.9435 - accuracy: 0.2774 - val_loss: 1.8474 - val_accuracy: 0.1992\n",
        "# Epoch 6/10\n",
        "# 31/31 [==============================] - 3s 100ms/step - loss: 1.8347 - accuracy: 0.2950 - val_loss: 1.8746 - val_accuracy: 0.2060\n",
        "# Epoch 7/10\n",
        "# 31/31 [==============================] - 3s 101ms/step - loss: 1.7898 - accuracy: 0.2743 - val_loss: 1.9190 - val_accuracy: 0.2074\n",
        "# Epoch 8/10\n",
        "# 31/31 [==============================] - 3s 106ms/step - loss: 1.7538 - accuracy: 0.3002 - val_loss: 1.9380 - val_accuracy: 0.2102\n",
        "# Epoch 9/10\n",
        "# 31/31 [==============================] - 3s 101ms/step - loss: 1.7069 - accuracy: 0.3126 - val_loss: 1.9870 - val_accuracy: 0.2033\n",
        "# Epoch 10/10\n",
        "# 31/31 [==============================] - 3s 98ms/step - loss: 1.6868 - accuracy: 0.2940 - val_loss: 1.9681 - val_accuracy: 0.2060\n",
        "# 31/31 [==============================] - 3s 51ms/step\n",
        "# 23/23 [==============================] - 1s 48ms/step\n",
        "# Validation Accuracy (SVM): 0.2087912087912088\n",
        "#                                      precision    recall  f1-score   support\n",
        "\n",
        "#                               ASC-H       0.11      0.06      0.08        63\n",
        "#                              ASC-US       0.20      0.26      0.23       145\n",
        "#                                HSIL       0.21      0.26      0.23       158\n",
        "#                                LSIL       0.23      0.23      0.23       146\n",
        "# Negative for intraepithelial lesion       0.21      0.22      0.22       153\n",
        "#                                 SCC       0.22      0.03      0.06        63\n",
        "\n",
        "#                            accuracy                           0.21       728\n",
        "#                           macro avg       0.20      0.18      0.17       728\n",
        "#                        weighted avg       0.21      0.21      0.20       728\n"
      ],
      "metadata": {
        "id": "KeuHTdp8ktEQ",
        "outputId": "7e222dc2-012d-4988-ae6b-3c772169b72a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanceamento das classes no conjunto de treino:\n",
            "Classe ASC-H: 67 amostras\n",
            "Classe ASC-US: 160 amostras\n",
            "Classe HSIL: 160 amostras\n",
            "Classe LSIL: 160 amostras\n",
            "Classe Negative for intraepithelial lesion: 160 amostras\n",
            "Classe SCC: 65 amostras\n",
            "Classe test: 4 amostras\n",
            "Classe train: 4 amostras\n",
            "Classe val: 4 amostras\n",
            "Balanceamento das classes no conjunto de teste:\n",
            "Classe ASC-H: 17 amostras\n",
            "Classe ASC-US: 40 amostras\n",
            "Classe HSIL: 40 amostras\n",
            "Classe LSIL: 40 amostras\n",
            "Classe Negative for intraepithelial lesion: 40 amostras\n",
            "Classe SCC: 17 amostras\n",
            "Classe test: 2 amostras\n",
            "Classe train: 2 amostras\n",
            "Classe val: 2 amostras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 4:\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_data(source_dir, train_dir, val_dir, test_dir, split_ratio=(0.7, 0.15, 0.15)):\n",
        "    for class_name in classes:\n",
        "        class_dir = os.path.join(source_dir, class_name)\n",
        "        images = os.listdir(class_dir)\n",
        "        random.shuffle(images)\n",
        "\n",
        "        train_split = int(split_ratio[0] * len(images))\n",
        "        val_split = int((split_ratio[0] + split_ratio[1]) * len(images))\n",
        "\n",
        "        train_images = images[:train_split]\n",
        "        val_images = images[train_split:val_split]\n",
        "        test_images = images[val_split:]\n",
        "\n",
        "        for image in train_images:\n",
        "            shutil.move(os.path.join(class_dir, image), os.path.join(train_dir, class_name, image))\n",
        "\n",
        "        for image in val_images:\n",
        "            shutil.move(os.path.join(class_dir, image), os.path.join(val_dir, class_name, image))\n",
        "\n",
        "        for image in test_images:\n",
        "            shutil.move(os.path.join(class_dir, image), os.path.join(test_dir, class_name, image))\n",
        "\n",
        "split_data(base_dir, train_dir, val_dir, test_dir)"
      ],
      "metadata": {
        "id": "zlJMfiFdnNvB"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pAjcLsvL6NRH"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5:\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Definir os caminhos para os dados de treinamento e validação\n",
        "train_dir = '/content/sub_images/sub_images/train'\n",
        "val_dir = '/content/sub_images/sub_images/val'\n",
        "test_dir = '/content/sub_images/sub_images/test'\n",
        "\n",
        "# Parâmetros\n",
        "img_height, img_width = 32, 32\n",
        "batch_size = 32\n",
        "num_classes = 6\n",
        "class_names = ['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative for intraepithelial lesion', 'SCC']\n",
        "\n",
        "# Criar um gerador de dados para carregar e pré-processar as imagens\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Carregar os dados de treinamento\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Carregar os dados de validação\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Carregar os dados de teste\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "# Carregar a ResNet50 pré-treinada\n",
        "base_model = ResNet50(weights=None, include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Adicionar camadas ao modelo\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Adicionando dropout\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # Ajustando a taxa de aprendizado\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator),\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Extrair características para treinamento e validação\n",
        "train_features = model.predict(train_generator)\n",
        "val_features = model.predict(val_generator)\n",
        "\n",
        "# Converter rótulos para uma única classe (não one-hot encoding)\n",
        "train_labels = train_generator.classes\n",
        "val_labels = val_generator.classes\n",
        "\n",
        "# Treinar o classificador SVM com hiperparâmetros ajustados\n",
        "svm = make_pipeline(StandardScaler(), SVC(kernel='rbf', C=100, gamma=0.1, probability=True))  # Ajustando os hiperparâmetros\n",
        "svm.fit(train_features, train_labels)\n",
        "\n",
        "# Avaliar o classificador SVM\n",
        "val_predictions = svm.predict(val_features)\n",
        "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
        "print('Validation Accuracy (SVM):', val_accuracy)\n",
        "print(classification_report(val_labels, val_predictions, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7m8o8ayia9F",
        "outputId": "25439664-c0a2-426a-a8a8-8b2213a45189"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 966 images belonging to 6 classes.\n",
            "Found 792 images belonging to 6 classes.\n",
            "Found 808 images belonging to 6 classes.\n",
            "Epoch 1/10\n",
            "31/31 [==============================] - 37s 225ms/step - loss: 2.9951 - accuracy: 0.1977 - val_loss: 1.7528 - val_accuracy: 0.1907\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 3s 108ms/step - loss: 2.5198 - accuracy: 0.2164 - val_loss: 1.7666 - val_accuracy: 0.2045\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 5s 149ms/step - loss: 2.2088 - accuracy: 0.2526 - val_loss: 1.8285 - val_accuracy: 0.1982\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 4s 116ms/step - loss: 2.0450 - accuracy: 0.2433 - val_loss: 1.8432 - val_accuracy: 0.2033\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 3s 109ms/step - loss: 1.9905 - accuracy: 0.2433 - val_loss: 1.8167 - val_accuracy: 0.2045\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 5s 148ms/step - loss: 1.8529 - accuracy: 0.3002 - val_loss: 1.8809 - val_accuracy: 0.2045\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 3s 107ms/step - loss: 1.7767 - accuracy: 0.2836 - val_loss: 1.8719 - val_accuracy: 0.2146\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 3s 107ms/step - loss: 1.7539 - accuracy: 0.3043 - val_loss: 1.9484 - val_accuracy: 0.1982\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 4s 123ms/step - loss: 1.7272 - accuracy: 0.2867 - val_loss: 1.9314 - val_accuracy: 0.2260\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 4s 136ms/step - loss: 1.6981 - accuracy: 0.2961 - val_loss: 1.8824 - val_accuracy: 0.2210\n",
            "31/31 [==============================] - 3s 51ms/step\n",
            "25/25 [==============================] - 1s 55ms/step\n",
            "Validation Accuracy (SVM): 0.18181818181818182\n",
            "                                     precision    recall  f1-score   support\n",
            "\n",
            "                              ASC-H       0.08      0.06      0.07        69\n",
            "                             ASC-US       0.18      0.22      0.20       162\n",
            "                               HSIL       0.18      0.21      0.19       168\n",
            "                               LSIL       0.20      0.21      0.21       157\n",
            "Negative for intraepithelial lesion       0.20      0.20      0.20       168\n",
            "                                SCC       0.13      0.03      0.05        68\n",
            "\n",
            "                           accuracy                           0.18       792\n",
            "                          macro avg       0.16      0.16      0.15       792\n",
            "                       weighted avg       0.18      0.18      0.18       792\n",
            "\n"
          ]
        }
      ]
    }
  ]
}