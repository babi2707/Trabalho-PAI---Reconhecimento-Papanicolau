{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babi2707/Trabalho-PAI---Reconhecimento-Papanicolau/blob/etapa2/algoritmo/backend/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 1:\n",
        "import zipfile\n",
        "\n",
        "caminho_pasta_compactada = '/content/sub_images.zip'\n",
        "caminho_destino = '/content/sub_images'\n",
        "\n",
        "with zipfile.ZipFile(caminho_pasta_compactada, 'r') as zip_ref:\n",
        "    zip_ref.extractall(caminho_destino)"
      ],
      "metadata": {
        "id": "fKGBtCoMnk8X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 2:\n",
        "import os\n",
        "\n",
        "base_dir = '/content/sub_images/sub_images'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Criar diretórios principais\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Criar subdiretórios para cada classe\n",
        "classes = ['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative for intraepithelial lesion', 'SCC']\n",
        "for class_name in classes:\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)"
      ],
      "metadata": {
        "id": "ZR8TdzBhnKl0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Célula 3.1:\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import os\n",
        "\n",
        "# # Diretório onde estão os dados\n",
        "# data_dir = '/content/sub_images/sub_images'\n",
        "\n",
        "# # Lista para armazenar os nomes dos arquivos e suas respectivas classes\n",
        "# file_names = []\n",
        "# labels = []\n",
        "\n",
        "# # Preencher as listas com os nomes dos arquivos e suas classes correspondentes\n",
        "# for class_name in os.listdir(data_dir):\n",
        "#     class_dir = os.path.join(data_dir, class_name)\n",
        "#     for file_name in os.listdir(class_dir):\n",
        "#         file_path = os.path.join(class_dir, file_name)\n",
        "#         file_names.append(file_path)\n",
        "#         labels.append(class_name)\n",
        "\n",
        "# # Dividir os dados em treino e validação (80% treino, 20% validação)\n",
        "# train_files, val_files, train_labels, val_labels = train_test_split(\n",
        "#     file_names, labels, test_size=0.2, stratify=labels, random_state=42\n",
        "# )\n",
        "\n",
        "# # Dividir os dados de treino em treino e teste (80% treino, 20% teste)\n",
        "# train_files, test_files, train_labels, test_labels = train_test_split(\n",
        "#     train_files, train_labels, test_size=0.2, stratify=train_labels, random_state=42\n",
        "# )\n",
        "\n",
        "# # Verificar o balanceamento das classes nos conjuntos de treino e teste\n",
        "# for dataset, dataset_name in zip([train_labels, test_labels], ['treino', 'teste']):\n",
        "#     unique, counts = np.unique(dataset, return_counts=True)\n",
        "#     print(f'Balanceamento das classes no conjunto de {dataset_name}:')\n",
        "#     for class_name, count in zip(unique, counts):\n",
        "#         print(f'Classe {class_name}: {count} amostras')\n",
        "\n",
        "# # Agora você tem:\n",
        "# # - train_files: lista de arquivos de treino\n",
        "# # - train_labels: lista de rótulos correspondentes de treino\n",
        "# # - val_files: lista de arquivos de validação\n",
        "# # - val_labels: lista de rótulos correspondentes de validação\n",
        "# # - test_files: lista de arquivos de teste\n",
        "# # - test_labels: lista de rótulos correspondentes de teste\n",
        "\n",
        "# #Resultados\n",
        "# # Found 966 images belonging to 6 classes.\n",
        "# # Found 685 images belonging to 6 classes.\n",
        "# # Found 704 images belonging to 6 classes.\n",
        "# # Epoch 1/10\n",
        "# # 31/31 [==============================] - 38s 158ms/step - loss: 2.9636 - accuracy: 0.2122 - val_loss: 1.7655 - val_accuracy: 0.2015\n",
        "# # Epoch 2/10\n",
        "# # 31/31 [==============================] - 3s 103ms/step - loss: 2.4541 - accuracy: 0.2402 - val_loss: 1.7478 - val_accuracy: 0.1985\n",
        "# # Epoch 3/10\n",
        "# # 31/31 [==============================] - 5s 156ms/step - loss: 2.2608 - accuracy: 0.2474 - val_loss: 1.7609 - val_accuracy: 0.1985\n",
        "# # Epoch 4/10\n",
        "# # 31/31 [==============================] - 3s 102ms/step - loss: 2.0217 - accuracy: 0.2826 - val_loss: 1.8062 - val_accuracy: 0.1985\n",
        "# # Epoch 5/10\n",
        "# # 31/31 [==============================] - 3s 100ms/step - loss: 1.9638 - accuracy: 0.2681 - val_loss: 1.7999 - val_accuracy: 0.1985\n",
        "# # Epoch 6/10\n",
        "# # 31/31 [==============================] - 3s 110ms/step - loss: 1.8415 - accuracy: 0.2867 - val_loss: 1.7896 - val_accuracy: 0.2234\n",
        "# # Epoch 7/10\n",
        "# # 31/31 [==============================] - 4s 143ms/step - loss: 1.8139 - accuracy: 0.2681 - val_loss: 1.7969 - val_accuracy: 0.2146\n",
        "# # Epoch 8/10\n",
        "# # 31/31 [==============================] - 3s 102ms/step - loss: 1.7435 - accuracy: 0.3033 - val_loss: 1.8410 - val_accuracy: 0.2219\n",
        "# # Epoch 9/10\n",
        "# # 31/31 [==============================] - 3s 105ms/step - loss: 1.7050 - accuracy: 0.2878 - val_loss: 1.8719 - val_accuracy: 0.2161\n",
        "# # Epoch 10/10\n",
        "# # 31/31 [==============================] - 5s 156ms/step - loss: 1.6880 - accuracy: 0.3095 - val_loss: 1.8447 - val_accuracy: 0.2263\n",
        "# # 31/31 [==============================] - 2s 51ms/step\n",
        "# # 22/22 [==============================] - 1s 49ms/step\n",
        "# # Validation Accuracy (SVM): 0.19416058394160585\n",
        "# #                                      precision    recall  f1-score   support\n",
        "\n",
        "# #                               ASC-H       0.11      0.08      0.09        60\n",
        "# #                              ASC-US       0.24      0.32      0.27       138\n",
        "# #                                HSIL       0.18      0.18      0.18       147\n",
        "# #                                LSIL       0.16      0.24      0.19       136\n",
        "# # Negative for intraepithelial lesion       0.25      0.16      0.19       144\n",
        "# #                                 SCC       0.16      0.05      0.08        60\n",
        "\n",
        "# #                            accuracy                           0.19       685\n",
        "# #                           macro avg       0.18      0.17      0.17       685\n",
        "# #                        weighted avg       0.19      0.19      0.19       685"
      ],
      "metadata": {
        "id": "x8Sr5yJVpc5G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 3.2:\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Diretório onde estão os dados\n",
        "data_dir = '/content/sub_images/sub_images'\n",
        "\n",
        "# Lista para armazenar os nomes dos arquivos e suas respectivas classes\n",
        "file_names = []\n",
        "labels = []\n",
        "\n",
        "# Preencher as listas com os nomes dos arquivos e suas classes correspondentes\n",
        "for class_name in os.listdir(data_dir):\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    for file_name in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, file_name)\n",
        "        file_names.append(file_path)\n",
        "        labels.append(class_name)\n",
        "\n",
        "# Dividir os dados em treino, validação e teste mantendo a proporção de 7:1.5:1.5\n",
        "train_files = []\n",
        "val_files = []\n",
        "test_files = []\n",
        "train_labels = []\n",
        "val_labels = []\n",
        "test_labels = []\n",
        "\n",
        "# Para cada classe, dividir os arquivos em treino, validação e teste mantendo a proporção de 7:1.5:1.5\n",
        "for class_name in set(labels):\n",
        "    # Obter os arquivos e rótulos da classe atual\n",
        "    class_files = [file for file, label in zip(file_names, labels) if label == class_name]\n",
        "    class_labels = [label for label in labels if label == class_name]\n",
        "\n",
        "    # Dividir os arquivos e rótulos em treino, validação e teste\n",
        "    class_train_files, class_test_val_files, class_train_labels, class_test_val_labels = train_test_split(\n",
        "        class_files, class_labels, test_size=0.3, random_state=42)\n",
        "    class_val_files, class_test_files, class_val_labels, class_test_labels = train_test_split(\n",
        "        class_test_val_files, class_test_val_labels, test_size=0.5, random_state=42)\n",
        "\n",
        "    # Adicionar os arquivos e rótulos aos conjuntos de treino, validação e teste\n",
        "    train_files.extend(class_train_files)\n",
        "    val_files.extend(class_val_files)\n",
        "    test_files.extend(class_test_files)\n",
        "    train_labels.extend(class_train_labels)\n",
        "    val_labels.extend(class_val_labels)\n",
        "    test_labels.extend(class_test_labels)\n",
        "\n",
        "# Verificar o balanceamento das classes nos conjuntos de treino, validação e teste\n",
        "for dataset, dataset_name in zip([train_labels, val_labels, test_labels], ['treino', 'validação', 'teste']):\n",
        "    unique, counts = np.unique(dataset, return_counts=True)\n",
        "    print(f'Balanceamento das classes no conjunto de {dataset_name}:')\n",
        "    for class_name, count in zip(unique, counts):\n",
        "        print(f'Classe {class_name}: {count} amostras')"
      ],
      "metadata": {
        "id": "KeuHTdp8ktEQ",
        "outputId": "9e1f6d9c-33c8-402a-c062-65b9d9a8bd9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanceamento das classes no conjunto de treino:\n",
            "Classe ASC-H: 58 amostras\n",
            "Classe ASC-US: 140 amostras\n",
            "Classe HSIL: 140 amostras\n",
            "Classe LSIL: 140 amostras\n",
            "Classe Negative for intraepithelial lesion: 140 amostras\n",
            "Classe SCC: 57 amostras\n",
            "Classe test: 4 amostras\n",
            "Classe train: 4 amostras\n",
            "Classe val: 4 amostras\n",
            "Balanceamento das classes no conjunto de validação:\n",
            "Classe ASC-H: 13 amostras\n",
            "Classe ASC-US: 30 amostras\n",
            "Classe HSIL: 30 amostras\n",
            "Classe LSIL: 30 amostras\n",
            "Classe Negative for intraepithelial lesion: 30 amostras\n",
            "Classe SCC: 12 amostras\n",
            "Classe test: 1 amostras\n",
            "Classe train: 1 amostras\n",
            "Classe val: 1 amostras\n",
            "Balanceamento das classes no conjunto de teste:\n",
            "Classe ASC-H: 13 amostras\n",
            "Classe ASC-US: 30 amostras\n",
            "Classe HSIL: 30 amostras\n",
            "Classe LSIL: 30 amostras\n",
            "Classe Negative for intraepithelial lesion: 30 amostras\n",
            "Classe SCC: 13 amostras\n",
            "Classe test: 1 amostras\n",
            "Classe train: 1 amostras\n",
            "Classe val: 1 amostras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Célula 3.3:\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import os\n",
        "# import numpy as np\n",
        "\n",
        "# # Diretório onde estão os dados\n",
        "# data_dir = '/content/sub_images/sub_images'\n",
        "\n",
        "# # Lista para armazenar os nomes dos arquivos e suas respectivas classes\n",
        "# file_names = []\n",
        "# labels = []\n",
        "\n",
        "# # Preencher as listas com os nomes dos arquivos e suas classes correspondentes\n",
        "# for class_name in os.listdir(data_dir):\n",
        "#     class_dir = os.path.join(data_dir, class_name)\n",
        "#     for file_name in os.listdir(class_dir):\n",
        "#         file_path = os.path.join(class_dir, file_name)\n",
        "#         file_names.append(file_path)\n",
        "#         labels.append(class_name)\n",
        "\n",
        "# # Dividir os dados em treino e teste mantendo a proporção de 4:1\n",
        "# train_files = []\n",
        "# test_files = []\n",
        "# train_labels = []\n",
        "# test_labels = []\n",
        "\n",
        "# # Para cada classe, dividir os arquivos em treino e teste mantendo a proporção de 4:1\n",
        "# for class_name in set(labels):\n",
        "#     # Obter os arquivos e rótulos da classe atual\n",
        "#     class_files = [file for file, label in zip(file_names, labels) if label == class_name]\n",
        "#     class_labels = [label for label in labels if label == class_name]\n",
        "\n",
        "#     # Dividir os arquivos e rótulos em treino e teste\n",
        "# class_train_files, class_test_files, class_train_labels, class_test_labels = train_test_split(\n",
        "#     class_files, class_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Convertendo os rótulos para binário corretamente\n",
        "# class_train_binary_labels = np.array([1 if label == 'Negative for intraepithelial lesion' else 0 for label in class_train_labels])\n",
        "# class_test_binary_labels = np.array([1 if label == 'Negative for intraepithelial lesion' else 0 for label in class_test_labels])\n",
        "\n",
        "# # Adicionar os arquivos e rótulos aos conjuntos de treino e teste\n",
        "# train_files.extend(class_train_files)\n",
        "# test_files.extend(class_test_files)\n",
        "# train_labels.extend(class_train_binary_labels)\n",
        "# test_labels.extend(class_test_binary_labels)\n",
        "\n",
        "\n",
        "# # Verificar o balanceamento das classes nos conjuntos de treino e teste\n",
        "# for dataset, dataset_name in zip([train_labels, test_labels], ['treino', 'teste']):\n",
        "#     unique, counts = np.unique(dataset, return_counts=True)\n",
        "#     print(f'Balanceamento das classes no conjunto de {dataset_name}:')\n",
        "#     for class_name, count in zip(unique, counts):\n",
        "#         print(f'Classe {class_name}: {count} amostras')\n",
        "\n",
        "# # Agora você tem:\n",
        "# # - train_files: lista de arquivos de treino\n",
        "# # - train_labels: lista de rótulos correspondentes de treino\n",
        "# # - test_files: lista de arquivos de teste\n",
        "# # - test_labels: lista de rótulos correspondentes de teste\n",
        "\n",
        "\n",
        "# #Resultados:\n",
        "# # Found 966 images belonging to 6 classes.\n",
        "# # Found 728 images belonging to 6 classes.\n",
        "# # Found 748 images belonging to 6 classes.\n",
        "# # Epoch 1/10\n",
        "# # 31/31 [==============================] - 35s 156ms/step - loss: 2.9200 - accuracy: 0.2112 - val_loss: 1.7805 - val_accuracy: 0.2102\n",
        "# # Epoch 2/10\n",
        "# # 31/31 [==============================] - 3s 110ms/step - loss: 2.4740 - accuracy: 0.2484 - val_loss: 1.7786 - val_accuracy: 0.2102\n",
        "# # Epoch 3/10\n",
        "# # 31/31 [==============================] - 3s 100ms/step - loss: 2.3013 - accuracy: 0.2516 - val_loss: 1.8061 - val_accuracy: 0.2102\n",
        "# # Epoch 4/10\n",
        "# # 31/31 [==============================] - 3s 99ms/step - loss: 2.0867 - accuracy: 0.2640 - val_loss: 1.8524 - val_accuracy: 0.2102\n",
        "# # Epoch 5/10\n",
        "# # 31/31 [==============================] - 5s 168ms/step - loss: 1.9435 - accuracy: 0.2774 - val_loss: 1.8474 - val_accuracy: 0.1992\n",
        "# # Epoch 6/10\n",
        "# # 31/31 [==============================] - 3s 100ms/step - loss: 1.8347 - accuracy: 0.2950 - val_loss: 1.8746 - val_accuracy: 0.2060\n",
        "# # Epoch 7/10\n",
        "# # 31/31 [==============================] - 3s 101ms/step - loss: 1.7898 - accuracy: 0.2743 - val_loss: 1.9190 - val_accuracy: 0.2074\n",
        "# # Epoch 8/10\n",
        "# # 31/31 [==============================] - 3s 106ms/step - loss: 1.7538 - accuracy: 0.3002 - val_loss: 1.9380 - val_accuracy: 0.2102\n",
        "# # Epoch 9/10\n",
        "# # 31/31 [==============================] - 3s 101ms/step - loss: 1.7069 - accuracy: 0.3126 - val_loss: 1.9870 - val_accuracy: 0.2033\n",
        "# # Epoch 10/10\n",
        "# # 31/31 [==============================] - 3s 98ms/step - loss: 1.6868 - accuracy: 0.2940 - val_loss: 1.9681 - val_accuracy: 0.2060\n",
        "# # 31/31 [==============================] - 3s 51ms/step\n",
        "# # 23/23 [==============================] - 1s 48ms/step\n",
        "# # Validation Accuracy (SVM): 0.2087912087912088\n",
        "# #                                      precision    recall  f1-score   support\n",
        "\n",
        "# #                               ASC-H       0.11      0.06      0.08        63\n",
        "# #                              ASC-US       0.20      0.26      0.23       145\n",
        "# #                                HSIL       0.21      0.26      0.23       158\n",
        "# #                                LSIL       0.23      0.23      0.23       146\n",
        "# # Negative for intraepithelial lesion       0.21      0.22      0.22       153\n",
        "# #                                 SCC       0.22      0.03      0.06        63\n",
        "\n",
        "# #                            accuracy                           0.21       728\n",
        "# #                           macro avg       0.20      0.18      0.17       728\n",
        "# #                        weighted avg       0.21      0.21      0.20       728\n"
      ],
      "metadata": {
        "id": "045Gv0FUKgSS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 4:\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_data(source_dir, train_dir, val_dir, test_dir, split_ratio=(0.7, 0.15, 0.15)):\n",
        "    for class_name in classes:\n",
        "        class_dir = os.path.join(source_dir, class_name)\n",
        "        images = os.listdir(class_dir)\n",
        "        random.shuffle(images)\n",
        "\n",
        "        train_split = int(split_ratio[0] * len(images))\n",
        "        val_split = int((split_ratio[0] + split_ratio[1]) * len(images))\n",
        "\n",
        "        train_images = images[:train_split]\n",
        "        val_images = images[train_split:val_split]\n",
        "        test_images = images[val_split:]\n",
        "\n",
        "        for image in train_images:\n",
        "            shutil.move(os.path.join(class_dir, image), os.path.join(train_dir, class_name, image))\n",
        "\n",
        "        for image in val_images:\n",
        "            shutil.move(os.path.join(class_dir, image), os.path.join(val_dir, class_name, image))\n",
        "\n",
        "        for image in test_images:\n",
        "            shutil.move(os.path.join(class_dir, image), os.path.join(test_dir, class_name, image))\n",
        "\n",
        "split_data(base_dir, train_dir, val_dir, test_dir)\n"
      ],
      "metadata": {
        "id": "zlJMfiFdnNvB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5:\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Definir os caminhos para os dados de treinamento e validação\n",
        "train_dir = '/content/sub_images/sub_images/train'\n",
        "val_dir = '/content/sub_images/sub_images/val'\n",
        "test_dir = '/content/sub_images/sub_images/test'\n",
        "\n",
        "# Parâmetros\n",
        "img_height, img_width = 224, 224  # Ajustar o tamanho das imagens para o input esperado pela ResNet50\n",
        "batch_size = 32\n",
        "num_classes = 6\n",
        "class_names = ['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative for intraepithelial lesion', 'SCC']\n",
        "\n",
        "# Criar um gerador de dados para carregar e pré-processar as imagens\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen_val_test = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Carregar os dados de treinamento\n",
        "train_generator = datagen_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Carregar os dados de validação\n",
        "val_generator = datagen_val_test.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Carregar os dados de teste\n",
        "test_generator = datagen_val_test.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Carregar a ResNet50 pré-treinada\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Adicionar camadas ao modelo\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Adicionando dropout\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Congelar as camadas da base_model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # Ajustando a taxa de aprendizado\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator),\n",
        "    epochs=20  # Aumentar o número de épocas\n",
        ")\n",
        "\n",
        "# Descongelar as camadas da base_model para fine-tuning\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompilar o modelo com uma taxa de aprendizado menor\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # Ajustando a taxa de aprendizado\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo novamente para fine-tuning\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator),\n",
        "    epochs=10  # Aumentar o número de épocas\n",
        ")\n",
        "\n",
        "# Avaliar o modelo nos dados de teste\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7m8o8ayia9F",
        "outputId": "6bb9ab97-c9cf-44aa-ce00-0194859187d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 675 images belonging to 6 classes.\n",
            "Found 145 images belonging to 6 classes.\n",
            "Found 146 images belonging to 6 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/20\n",
            "22/22 [==============================] - 167s 7s/step - loss: 1.9345 - accuracy: 0.2119 - val_loss: 1.7309 - val_accuracy: 0.2207\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 167s 8s/step - loss: 1.9241 - accuracy: 0.1896 - val_loss: 1.7252 - val_accuracy: 0.2069\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 154s 7s/step - loss: 1.9247 - accuracy: 0.1881 - val_loss: 1.7191 - val_accuracy: 0.2345\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 152s 7s/step - loss: 1.8750 - accuracy: 0.2252 - val_loss: 1.7186 - val_accuracy: 0.2483\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 158s 7s/step - loss: 1.8422 - accuracy: 0.2326 - val_loss: 1.7132 - val_accuracy: 0.3034\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 152s 7s/step - loss: 1.8451 - accuracy: 0.1896 - val_loss: 1.7156 - val_accuracy: 0.2966\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 151s 7s/step - loss: 1.8593 - accuracy: 0.1763 - val_loss: 1.7115 - val_accuracy: 0.2345\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 153s 7s/step - loss: 1.7755 - accuracy: 0.2430 - val_loss: 1.7049 - val_accuracy: 0.2138\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 153s 7s/step - loss: 1.7724 - accuracy: 0.2385 - val_loss: 1.7059 - val_accuracy: 0.2552\n",
            "Epoch 10/20\n",
            " 8/22 [=========>....................] - ETA: 1:13 - loss: 1.7456 - accuracy: 0.2070"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultados com rede neural modificada:\n",
        "# Found 964 images belonging to 6 classes.\n",
        "# Found 537 images belonging to 6 classes.\n",
        "# Found 539 images belonging to 6 classes.\n",
        "# Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "# 94765736/94765736 [==============================] - 1s 0us/step\n",
        "# Epoch 1/10\n",
        "# 31/31 [==============================] - 873s 27s/step - loss: 1.4912 - accuracy: 0.4098 - val_loss: 2.8945 - val_accuracy: 0.2030\n",
        "# Epoch 2/10\n",
        "# 31/31 [==============================] - 855s 28s/step - loss: 1.1226 - accuracy: 0.5249 - val_loss: 2.3391 - val_accuracy: 0.2067\n",
        "# Epoch 3/10\n",
        "# 31/31 [==============================] - 847s 27s/step - loss: 0.9512 - accuracy: 0.6027 - val_loss: 2.1949 - val_accuracy: 0.1825\n",
        "# Epoch 4/10\n",
        "# 31/31 [==============================] - 847s 27s/step - loss: 0.8555 - accuracy: 0.6162 - val_loss: 2.1916 - val_accuracy: 0.1993\n",
        "# Epoch 5/10\n",
        "# 31/31 [==============================] - 848s 27s/step - loss: 0.7774 - accuracy: 0.6846 - val_loss: 2.2463 - val_accuracy: 0.1993\n",
        "# Epoch 6/10\n",
        "# 31/31 [==============================] - 841s 28s/step - loss: 0.7329 - accuracy: 0.6981 - val_loss: 2.5806 - val_accuracy: 0.1993\n",
        "# Epoch 7/10\n",
        "# 31/31 [==============================] - 847s 27s/step - loss: 0.6286 - accuracy: 0.7355 - val_loss: 2.0137 - val_accuracy: 0.2030\n",
        "# Epoch 8/10\n",
        "# 31/31 [==============================] - 874s 28s/step - loss: 0.5590 - accuracy: 0.7811 - val_loss: 2.0829 - val_accuracy: 0.1993\n",
        "# Epoch 9/10\n",
        "# 31/31 [==============================] - 857s 28s/step - loss: 0.5036 - accuracy: 0.8091 - val_loss: 1.9304 - val_accuracy: 0.2235\n",
        "# Epoch 10/10\n",
        "# 31/31 [==============================] - 853s 28s/step - loss: 0.4683 - accuracy: 0.8195 - val_loss: 1.9530 - val_accuracy: 0.2235\n",
        "# 17/17 [==============================] - 114s 7s/step - loss: 1.9962 - accuracy: 0.2041\n",
        "# Test accuracy: 0.20408163964748383\n",
        "\n",
        "\n",
        "# Resultados sem rede neural completa:\n",
        "\n",
        "# Found 953 images belonging to 6 classes.\n",
        "# Found 455 images belonging to 6 classes.\n",
        "# Found 460 images belonging to 6 classes.\n",
        "# Epoch 1/10\n",
        "# 30/30 [==============================] - 97s 2s/step - loss: 3.0401 - accuracy: 0.2099 - val_loss: 1.7510 - val_accuracy: 0.2176\n",
        "# Epoch 2/10\n",
        "# 30/30 [==============================] - 72s 2s/step - loss: 2.4821 - accuracy: 0.2371 - val_loss: 1.7373 - val_accuracy: 0.2176\n",
        "# Epoch 3/10\n",
        "# 30/30 [==============================] - 72s 2s/step - loss: 2.2958 - accuracy: 0.2550 - val_loss: 1.7610 - val_accuracy: 0.2044\n",
        "# Epoch 4/10\n",
        "# 30/30 [==============================] - 72s 2s/step - loss: 2.0778 - accuracy: 0.2697 - val_loss: 1.7802 - val_accuracy: 0.2176\n",
        "# Epoch 5/10\n",
        "# 30/30 [==============================] - 73s 2s/step - loss: 1.9995 - accuracy: 0.2445 - val_loss: 1.7836 - val_accuracy: 0.2154\n",
        "# Epoch 6/10\n",
        "# 30/30 [==============================] - 72s 2s/step - loss: 1.8464 - accuracy: 0.2686 - val_loss: 1.7934 - val_accuracy: 0.2000\n",
        "# Epoch 7/10\n",
        "# 30/30 [==============================] - 72s 2s/step - loss: 1.8197 - accuracy: 0.2802 - val_loss: 1.7988 - val_accuracy: 0.2352\n",
        "# Epoch 8/10\n",
        "# 30/30 [==============================] - 72s 2s/step - loss: 1.7412 - accuracy: 0.2917 - val_loss: 1.7798 - val_accuracy: 0.2022\n",
        "# Epoch 9/10\n",
        "# 30/30 [==============================] - 72s 2s/step - loss: 1.6624 - accuracy: 0.3064 - val_loss: 1.8088 - val_accuracy: 0.2132\n",
        "# Epoch 10/10\n",
        "# 30/30 [==============================] - 73s 2s/step - loss: 1.6544 - accuracy: 0.3095 - val_loss: 1.8197 - val_accuracy: 0.2308\n",
        "# 30/30 [==============================] - 8s 233ms/step\n",
        "# 15/15 [==============================] - 2s 158ms/step\n",
        "# Validation Accuracy (SVM): 0.2021978021978022\n",
        "#                                      precision    recall  f1-score   support\n",
        "\n",
        "#                               ASC-H       0.00      0.00      0.00        44\n",
        "#                              ASC-US       0.26      0.31      0.28        99\n",
        "#                                HSIL       0.16      0.21      0.18        90\n",
        "#                                LSIL       0.24      0.27      0.25        93\n",
        "# Negative for intraepithelial lesion       0.18      0.18      0.18        91\n",
        "#                                 SCC       0.14      0.03      0.04        38\n",
        "\n",
        "#                            accuracy                           0.20       455\n",
        "#                           macro avg       0.16      0.17      0.16       455\n",
        "#                        weighted avg       0.18      0.20      0.19       455"
      ],
      "metadata": {
        "id": "jyJ5nloCeaS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 6:\n",
        "# Extrair características para treinamento e validação\n",
        "train_features = model.predict(train_generator)\n",
        "val_features = model.predict(val_generator)\n",
        "\n",
        "# Converter rótulos para uma única classe (não one-hot encoding)\n",
        "train_labels = train_generator.classes\n",
        "val_labels = val_generator.classes\n",
        "\n",
        "# Treinar o classificador SVM com hiperparâmetros ajustados\n",
        "svm = make_pipeline(StandardScaler(), SVC(kernel='rbf', C=100, gamma=0.1, probability=True))  # Ajustando os hiperparâmetros\n",
        "svm.fit(train_features, train_labels)\n",
        "\n",
        "# Avaliar o classificador SVM\n",
        "val_predictions = svm.predict(val_features)\n",
        "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
        "print('Validation Accuracy (SVM):', val_accuracy)\n",
        "print(classification_report(val_labels, val_predictions, target_names=class_names))\n",
        "\n",
        "# Avaliar o classificador SVM nos dados de teste\n",
        "test_features = model.predict(test_generator)\n",
        "test_labels = test_generator.classes\n",
        "test_predictions = svm.predict(test_features)\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "print('Test Accuracy (SVM):', test_accuracy)\n",
        "print(classification_report(test_labels, test_predictions, target_names=class_names))"
      ],
      "metadata": {
        "id": "TJJdgECAghLB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}