{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babi2707/Trabalho-PAI---Reconhecimento-Papanicolau/blob/main/algoritmo/backend/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 1:\n",
        "import zipfile\n",
        "\n",
        "caminho_pasta_compactada = '/content/sub_images.zip'\n",
        "caminho_destino = '/content/sub_images'\n",
        "\n",
        "with zipfile.ZipFile(caminho_pasta_compactada, 'r') as zip_ref:\n",
        "    zip_ref.extractall(caminho_destino)\n"
      ],
      "metadata": {
        "id": "fKGBtCoMnk8X"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 2:\n",
        "import os\n",
        "\n",
        "base_dir = '/content/sub_images/sub_images'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Criar diretórios principais\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Criar subdiretórios para cada classe\n",
        "classes = ['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative for intraepithelial lesion', 'SCC']\n",
        "for class_name in classes:\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n"
      ],
      "metadata": {
        "id": "ZR8TdzBhnKl0"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Célula 3.1:\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import os\n",
        "\n",
        "# # Diretório onde estão os dados\n",
        "# data_dir = '/content/sub_images/sub_images'\n",
        "\n",
        "# # Lista para armazenar os nomes dos arquivos e suas respectivas classes\n",
        "# file_names = []\n",
        "# labels = []\n",
        "\n",
        "# # Preencher as listas com os nomes dos arquivos e suas classes correspondentes\n",
        "# for class_name in os.listdir(data_dir):\n",
        "#     class_dir = os.path.join(data_dir, class_name)\n",
        "#     for file_name in os.listdir(class_dir):\n",
        "#         file_path = os.path.join(class_dir, file_name)\n",
        "#         file_names.append(file_path)\n",
        "#         labels.append(class_name)\n",
        "\n",
        "# # Dividir os dados em treino e validação (80% treino, 20% validação)\n",
        "# train_files, val_files, train_labels, val_labels = train_test_split(\n",
        "#     file_names, labels, test_size=0.2, stratify=labels, random_state=42\n",
        "# )\n",
        "\n",
        "# # Dividir os dados de treino em treino e teste (80% treino, 20% teste)\n",
        "# train_files, test_files, train_labels, test_labels = train_test_split(\n",
        "#     train_files, train_labels, test_size=0.2, stratify=train_labels, random_state=42\n",
        "# )\n",
        "\n",
        "# # Verificar o balanceamento das classes nos conjuntos de treino e teste\n",
        "# for dataset, dataset_name in zip([train_labels, test_labels], ['treino', 'teste']):\n",
        "#     unique, counts = np.unique(dataset, return_counts=True)\n",
        "#     print(f'Balanceamento das classes no conjunto de {dataset_name}:')\n",
        "#     for class_name, count in zip(unique, counts):\n",
        "#         print(f'Classe {class_name}: {count} amostras')\n",
        "\n",
        "# # Agora você tem:\n",
        "# # - train_files: lista de arquivos de treino\n",
        "# # - train_labels: lista de rótulos correspondentes de treino\n",
        "# # - val_files: lista de arquivos de validação\n",
        "# # - val_labels: lista de rótulos correspondentes de validação\n",
        "# # - test_files: lista de arquivos de teste\n",
        "# # - test_labels: lista de rótulos correspondentes de teste\n",
        "\n",
        "\n",
        "\n",
        "# #Resultados\n",
        "# # Found 966 images belonging to 6 classes.\n",
        "# # Found 685 images belonging to 6 classes.\n",
        "# # Found 704 images belonging to 6 classes.\n",
        "# # Epoch 1/10\n",
        "# # 31/31 [==============================] - 38s 158ms/step - loss: 2.9636 - accuracy: 0.2122 - val_loss: 1.7655 - val_accuracy: 0.2015\n",
        "# # Epoch 2/10\n",
        "# # 31/31 [==============================] - 3s 103ms/step - loss: 2.4541 - accuracy: 0.2402 - val_loss: 1.7478 - val_accuracy: 0.1985\n",
        "# # Epoch 3/10\n",
        "# # 31/31 [==============================] - 5s 156ms/step - loss: 2.2608 - accuracy: 0.2474 - val_loss: 1.7609 - val_accuracy: 0.1985\n",
        "# # Epoch 4/10\n",
        "# # 31/31 [==============================] - 3s 102ms/step - loss: 2.0217 - accuracy: 0.2826 - val_loss: 1.8062 - val_accuracy: 0.1985\n",
        "# # Epoch 5/10\n",
        "# # 31/31 [==============================] - 3s 100ms/step - loss: 1.9638 - accuracy: 0.2681 - val_loss: 1.7999 - val_accuracy: 0.1985\n",
        "# # Epoch 6/10\n",
        "# # 31/31 [==============================] - 3s 110ms/step - loss: 1.8415 - accuracy: 0.2867 - val_loss: 1.7896 - val_accuracy: 0.2234\n",
        "# # Epoch 7/10\n",
        "# # 31/31 [==============================] - 4s 143ms/step - loss: 1.8139 - accuracy: 0.2681 - val_loss: 1.7969 - val_accuracy: 0.2146\n",
        "# # Epoch 8/10\n",
        "# # 31/31 [==============================] - 3s 102ms/step - loss: 1.7435 - accuracy: 0.3033 - val_loss: 1.8410 - val_accuracy: 0.2219\n",
        "# # Epoch 9/10\n",
        "# # 31/31 [==============================] - 3s 105ms/step - loss: 1.7050 - accuracy: 0.2878 - val_loss: 1.8719 - val_accuracy: 0.2161\n",
        "# # Epoch 10/10\n",
        "# # 31/31 [==============================] - 5s 156ms/step - loss: 1.6880 - accuracy: 0.3095 - val_loss: 1.8447 - val_accuracy: 0.2263\n",
        "# # 31/31 [==============================] - 2s 51ms/step\n",
        "# # 22/22 [==============================] - 1s 49ms/step\n",
        "# # Validation Accuracy (SVM): 0.19416058394160585\n",
        "# #                                      precision    recall  f1-score   support\n",
        "\n",
        "# #                               ASC-H       0.11      0.08      0.09        60\n",
        "# #                              ASC-US       0.24      0.32      0.27       138\n",
        "# #                                HSIL       0.18      0.18      0.18       147\n",
        "# #                                LSIL       0.16      0.24      0.19       136\n",
        "# # Negative for intraepithelial lesion       0.25      0.16      0.19       144\n",
        "# #                                 SCC       0.16      0.05      0.08        60\n",
        "\n",
        "# #                            accuracy                           0.19       685\n",
        "# #                           macro avg       0.18      0.17      0.17       685\n",
        "# #                        weighted avg       0.19      0.19      0.19       685"
      ],
      "metadata": {
        "id": "4dpHaC-tceI7",
        "outputId": "4e52c648-82d7-4320-d258-58202be97fd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanceamento das classes no conjunto de treino:\n",
            "Classe ASC-H: 53 amostras\n",
            "Classe ASC-US: 128 amostras\n",
            "Classe HSIL: 128 amostras\n",
            "Classe LSIL: 128 amostras\n",
            "Classe Negative for intraepithelial lesion: 128 amostras\n",
            "Classe SCC: 52 amostras\n",
            "Classe test: 4 amostras\n",
            "Classe train: 4 amostras\n",
            "Classe val: 4 amostras\n",
            "Balanceamento das classes no conjunto de teste:\n",
            "Classe ASC-H: 14 amostras\n",
            "Classe ASC-US: 32 amostras\n",
            "Classe HSIL: 32 amostras\n",
            "Classe LSIL: 32 amostras\n",
            "Classe Negative for intraepithelial lesion: 32 amostras\n",
            "Classe SCC: 13 amostras\n",
            "Classe test: 1 amostras\n",
            "Classe train: 1 amostras\n",
            "Classe val: 1 amostras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 3.2:\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Diretório onde estão os dados\n",
        "data_dir = '/content/sub_images/sub_images'\n",
        "\n",
        "# Lista para armazenar os nomes dos arquivos e suas respectivas classes\n",
        "file_names = []\n",
        "labels = []\n",
        "\n",
        "# Preencher as listas com os nomes dos arquivos e suas classes correspondentes\n",
        "for class_name in os.listdir(data_dir):\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    for file_name in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, file_name)\n",
        "        file_names.append(file_path)\n",
        "        labels.append(class_name)\n",
        "\n",
        "# Dividir os dados em treino e teste (80% treino, 20% teste)\n",
        "train_files, test_files, train_labels, test_labels = train_test_split(\n",
        "    file_names, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# Verificar o balanceamento das classes nos conjuntos de treino e teste\n",
        "for dataset, dataset_name in zip([train_labels, test_labels], ['treino', 'teste']):\n",
        "    unique, counts = np.unique(dataset, return_counts=True)\n",
        "    print(f'Balanceamento das classes no conjunto de {dataset_name}:')\n",
        "    for class_name, count in zip(unique, counts):\n",
        "        print(f'Classe {class_name}: {count} amostras')\n",
        "\n",
        "# Agora você tem:\n",
        "# - train_files: lista de arquivos de treino\n",
        "# - train_labels: lista de rótulos correspondentes de treino\n",
        "# - test_files: lista de arquivos de teste\n",
        "# - test_labels: lista de rótulos correspondentes de teste\n",
        "\n",
        "#Resultados:\n",
        "# Found 966 images belonging to 6 classes.\n",
        "# Found 643 images belonging to 6 classes.\n",
        "# Found 656 images belonging to 6 classes.\n",
        "# Epoch 1/10\n",
        "# 31/31 [==============================] - 36s 172ms/step - loss: 3.1935 - accuracy: 0.1801 - val_loss: 1.7733 - val_accuracy: 0.1991\n",
        "# Epoch 2/10\n",
        "# 31/31 [==============================] - 4s 144ms/step - loss: 2.3475 - accuracy: 0.2733 - val_loss: 1.7861 - val_accuracy: 0.1991\n",
        "# Epoch 3/10\n",
        "# 31/31 [==============================] - 3s 104ms/step - loss: 2.2693 - accuracy: 0.2516 - val_loss: 1.7892 - val_accuracy: 0.2053\n",
        "# Epoch 4/10\n",
        "# 31/31 [==============================] - 3s 100ms/step - loss: 2.0218 - accuracy: 0.2557 - val_loss: 1.7805 - val_accuracy: 0.1991\n",
        "# Epoch 5/10\n",
        "# 31/31 [==============================] - 4s 136ms/step - loss: 1.9547 - accuracy: 0.2743 - val_loss: 1.8247 - val_accuracy: 0.2053\n",
        "# Epoch 6/10\n",
        "# 31/31 [==============================] - 3s 102ms/step - loss: 1.8596 - accuracy: 0.2743 - val_loss: 1.8279 - val_accuracy: 0.1975\n",
        "# Epoch 7/10\n",
        "# 31/31 [==============================] - 3s 101ms/step - loss: 1.8265 - accuracy: 0.2619 - val_loss: 1.8671 - val_accuracy: 0.1991\n",
        "# Epoch 8/10\n",
        "# 31/31 [==============================] - 4s 137ms/step - loss: 1.7337 - accuracy: 0.2950 - val_loss: 1.9080 - val_accuracy: 0.2022\n",
        "# Epoch 9/10\n",
        "# 31/31 [==============================] - 3s 100ms/step - loss: 1.7119 - accuracy: 0.2992 - val_loss: 1.9506 - val_accuracy: 0.2115\n",
        "# Epoch 10/10\n",
        "# 31/31 [==============================] - 3s 101ms/step - loss: 1.6747 - accuracy: 0.3178 - val_loss: 2.0451 - val_accuracy: 0.1788\n",
        "# 31/31 [==============================] - 2s 49ms/step\n",
        "# 21/21 [==============================] - 1s 61ms/step\n",
        "# Validation Accuracy (SVM): 0.19595645412130638\n",
        "#                                      precision    recall  f1-score   support\n",
        "\n",
        "#                               ASC-H       0.12      0.05      0.07        57\n",
        "#                              ASC-US       0.20      0.28      0.24       131\n",
        "#                                HSIL       0.16      0.20      0.18       136\n",
        "#                                LSIL       0.23      0.23      0.23       128\n",
        "# Negative for intraepithelial lesion       0.20      0.19      0.20       132\n",
        "#                                 SCC       0.22      0.07      0.10        59\n",
        "\n",
        "#                            accuracy                           0.20       643\n",
        "#                           macro avg       0.19      0.17      0.17       643\n",
        "#                        weighted avg       0.20      0.20      0.19       643\n"
      ],
      "metadata": {
        "id": "x8Sr5yJVpc5G"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 4:\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_data(source_dir, train_dir, val_dir, test_dir, split_ratio=(0.7, 0.15, 0.15)):\n",
        "    for class_name in classes:\n",
        "        class_dir = os.path.join(source_dir, class_name)\n",
        "        images = os.listdir(class_dir)\n",
        "        random.shuffle(images)\n",
        "\n",
        "        train_split = int(split_ratio[0] * len(images))\n",
        "        val_split = int((split_ratio[0] + split_ratio[1]) * len(images))\n",
        "\n",
        "        train_images = images[:train_split]\n",
        "        val_images = images[train_split:val_split]\n",
        "        test_images = images[val_split:]\n",
        "\n",
        "        for image in train_images:\n",
        "            shutil.move(os.path.join(class_dir, image), os.path.join(train_dir, class_name, image))\n",
        "\n",
        "        for image in val_images:\n",
        "            shutil.move(os.path.join(class_dir, image), os.path.join(val_dir, class_name, image))\n",
        "\n",
        "        for image in test_images:\n",
        "            shutil.move(os.path.join(class_dir, image), os.path.join(test_dir, class_name, image))\n",
        "\n",
        "split_data(base_dir, train_dir, val_dir, test_dir)\n"
      ],
      "metadata": {
        "id": "zlJMfiFdnNvB"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5:\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Definir os caminhos para os dados de treinamento e validação\n",
        "train_dir = '/content/sub_images/sub_images/train'\n",
        "val_dir = '/content/sub_images/sub_images/val'\n",
        "test_dir = '/content/sub_images/sub_images/test'\n",
        "\n",
        "# Parâmetros\n",
        "img_height, img_width = 32, 32\n",
        "batch_size = 32\n",
        "num_classes = 6\n",
        "class_names = ['ASC-H', 'ASC-US', 'HSIL', 'LSIL', 'Negative for intraepithelial lesion', 'SCC']\n",
        "\n",
        "# Criar um gerador de dados para carregar e pré-processar as imagens\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Carregar os dados de treinamento\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Carregar os dados de validação\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Carregar os dados de teste\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "# Carregar a ResNet50 pré-treinada\n",
        "base_model = ResNet50(weights=None, include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Adicionar camadas ao modelo\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Adicionando dropout\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # Ajustando a taxa de aprendizado\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator),\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Extrair características para treinamento e validação\n",
        "train_features = model.predict(train_generator)\n",
        "val_features = model.predict(val_generator)\n",
        "\n",
        "# Converter rótulos para uma única classe (não one-hot encoding)\n",
        "train_labels = train_generator.classes\n",
        "val_labels = val_generator.classes\n",
        "\n",
        "# Treinar o classificador SVM com hiperparâmetros ajustados\n",
        "svm = make_pipeline(StandardScaler(), SVC(kernel='rbf', C=100, gamma=0.1, probability=True))  # Ajustando os hiperparâmetros\n",
        "svm.fit(train_features, train_labels)\n",
        "\n",
        "# Avaliar o classificador SVM\n",
        "val_predictions = svm.predict(val_features)\n",
        "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
        "print('Validation Accuracy (SVM):', val_accuracy)\n",
        "print(classification_report(val_labels, val_predictions, target_names=class_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7m8o8ayia9F",
        "outputId": "58fa6ba4-6913-40e4-c67e-10062e2e5c2f"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 966 images belonging to 6 classes.\n",
            "Found 685 images belonging to 6 classes.\n",
            "Found 704 images belonging to 6 classes.\n",
            "Epoch 1/10\n",
            "31/31 [==============================] - 38s 158ms/step - loss: 2.9636 - accuracy: 0.2122 - val_loss: 1.7655 - val_accuracy: 0.2015\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 3s 103ms/step - loss: 2.4541 - accuracy: 0.2402 - val_loss: 1.7478 - val_accuracy: 0.1985\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 2.2608 - accuracy: 0.2474 - val_loss: 1.7609 - val_accuracy: 0.1985\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 2.0217 - accuracy: 0.2826 - val_loss: 1.8062 - val_accuracy: 0.1985\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 1.9638 - accuracy: 0.2681 - val_loss: 1.7999 - val_accuracy: 0.1985\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 3s 110ms/step - loss: 1.8415 - accuracy: 0.2867 - val_loss: 1.7896 - val_accuracy: 0.2234\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 4s 143ms/step - loss: 1.8139 - accuracy: 0.2681 - val_loss: 1.7969 - val_accuracy: 0.2146\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 1.7435 - accuracy: 0.3033 - val_loss: 1.8410 - val_accuracy: 0.2219\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 3s 105ms/step - loss: 1.7050 - accuracy: 0.2878 - val_loss: 1.8719 - val_accuracy: 0.2161\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.6880 - accuracy: 0.3095 - val_loss: 1.8447 - val_accuracy: 0.2263\n",
            "31/31 [==============================] - 2s 51ms/step\n",
            "22/22 [==============================] - 1s 49ms/step\n",
            "Validation Accuracy (SVM): 0.19416058394160585\n",
            "                                     precision    recall  f1-score   support\n",
            "\n",
            "                              ASC-H       0.11      0.08      0.09        60\n",
            "                             ASC-US       0.24      0.32      0.27       138\n",
            "                               HSIL       0.18      0.18      0.18       147\n",
            "                               LSIL       0.16      0.24      0.19       136\n",
            "Negative for intraepithelial lesion       0.25      0.16      0.19       144\n",
            "                                SCC       0.16      0.05      0.08        60\n",
            "\n",
            "                           accuracy                           0.19       685\n",
            "                          macro avg       0.18      0.17      0.17       685\n",
            "                       weighted avg       0.19      0.19      0.19       685\n",
            "\n"
          ]
        }
      ]
    }
  ]
}